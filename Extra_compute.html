<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Computational resources outside of Mila &mdash; MILA Technical Documentation latest documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/documentation_options.js"></script>
        <script src="_static/documentation_options_fix.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="User’s guide" href="Userguide.html" />
    <link rel="prev" title="Computing infrastructure and policies" href="Information.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/image.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                latest
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Purpose.html">Purpose of this documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Purpose.html#contributing">Contributing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">General theory</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html">What is a computer cluster?</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html#parts-of-a-computing-cluster">Parts of a computing cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html#unix">UNIX</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html#the-workload-manager">The workload manager</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html#processing-data">Processing data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Theory_cluster.html#software-on-the-cluster">Software on the cluster</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Systems and services</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Information.html">Computing infrastructure and policies</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Computational resources outside of Mila</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#compute-canada-clusters">Compute Canada Clusters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#current-allocation-description">Current allocation description</a></li>
<li class="toctree-l3"><a class="reference internal" href="#account-creation">Account Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#clusters">Clusters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#beluga">Beluga</a></li>
<li class="toctree-l4"><a class="reference internal" href="#graham">Graham</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cedar">Cedar</a></li>
<li class="toctree-l4"><a class="reference internal" href="#niagara">Niagara</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#faq">FAQ</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#what-to-do-with-importerror-lib64-libm-so-6-version-glibc-2-23-not-found">What to do with  <cite>ImportError: /lib64/libm.so.6: version GLIBC_2.23 not found</cite>?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#disk-quota-exceeded-error-on-project-file-systems">Disk quota exceeded error on <code class="docutils literal notranslate"><span class="pre">/project</span></code> file systems</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">How-tos and Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Userguide.html">User’s guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Handbook.html">AI tooling and methodology handbook</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extras</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Audio_video.html">Audio and video resources at Mila</a></li>
<li class="toctree-l1"><a class="reference internal" href="VSCode.html">Visual Studio Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="IDT.html">Who, what, where is IDT</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MILA Technical Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Computational resources outside of Mila</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/mila-iqia/mila-docs/blob/master/docs/Extra_compute.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="computational-resources-outside-of-mila">
<h1>Computational resources outside of Mila<a class="headerlink" href="#computational-resources-outside-of-mila" title="Permalink to this heading"></a></h1>
<p>This section seeks to provide insights and information on computational
resources outside the Mila cluster itself.</p>
<section id="compute-canada-clusters">
<span id="cc-clusters"></span><h2>Compute Canada Clusters<a class="headerlink" href="#compute-canada-clusters" title="Permalink to this heading"></a></h2>
<p>The clusters named <cite>Beluga</cite>, <cite>Cedar</cite>, <cite>Graham</cite>, <cite>Narval</cite> and <cite>Niagara</cite> are
clusters provided by the <a class="reference external" href="https://www.computecanada.ca">Compute Canada organisation</a>. For Mila researchers, these clusters are to
be used for larger experiments having many jobs, multi-node computation and/or
multi-GPU jobs as well as long running jobs.</p>
<section id="current-allocation-description">
<h3>Current allocation description<a class="headerlink" href="#current-allocation-description" title="Permalink to this heading"></a></h3>
<p>Clusters of Compute Canada are shared with researchers across the country.
Allocations are given by Compute Canada to selected research groups to ensure
to a minimal amount of computational resources throughout the year.</p>
<p>Depending on your affiliation, you will have access to different allocations. If
you are a student at University of Montreal, you can have access to the
<code class="docutils literal notranslate"><span class="pre">rrg-bengioy-ad</span></code> allocation described below. For students from other
universities, you should ask your advisor to know which allocations you could
have access to.</p>
<p>From Compute Canada’s documentation: <cite>An allocation is an amount of
resources that a research group can target for use for a period of
time, usually a year.</cite> To be clear, it is not a maximal amount of
resources that can be used simultaneously, it is a weighting factor of
the workload manager to balance jobs.  For instance, even though we
are allocated 400 GPU-years across all clusters, we can use more or less than
400 GPUs simultaneously depending on the history of usage from our
group and other groups using the cluster at a given period of time.
Please see Compute Canada’s <a class="reference external" href="https://docs.computecanada.ca/wiki/Allocations_and_resource_scheduling">documentation</a>
for more information on how allocations and resource scheduling are
configured for these installations.</p>
<p>The table below provides information on the allocation for
<code class="docutils literal notranslate"><span class="pre">rrg-bengioy-ad</span></code> for the period which spans from April 2022 to
April 2023. Note that there are no special allocations for GPUs on
Graham and therefore jobs with GPUs should be submitted with the
account <code class="docutils literal notranslate"><span class="pre">def-bengioy</span></code>.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 24%" />
<col style="width: 6%" />
<col style="width: 16%" />
<col style="width: 11%" />
<col style="width: 5%" />
<col style="width: 22%" />
<col style="width: 16%" />
</colgroup>
<tbody>
<tr class="row-odd"><td rowspan="2"><p>Cluster</p></td>
<td colspan="2"><p>CPUs</p></td>
<td colspan="4"><p>GPUs</p></td>
</tr>
<tr class="row-even"><td><p>#</p></td>
<td><p>account</p></td>
<td><p>Model</p></td>
<td><p>#</p></td>
<td><p>SLURM type specifier</p></td>
<td><p>account</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#beluga"><span class="std std-ref">Beluga</span></a></p></td>
<td><p>238</p></td>
<td><p>rrg-bengioy-ad</p></td>
<td><p>V100-16G</p></td>
<td><p>77</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">v100</span></code></p></td>
<td><p>rrg-bengioy-ad</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#cedar"><span class="std std-ref">Cedar</span></a></p></td>
<td><p>34</p></td>
<td><p>rrg-bengioy-ad</p></td>
<td><p>V100-32G</p></td>
<td><p>138</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">v100l</span></code></p></td>
<td><p>rrg-bengioy-ad</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#graham"><span class="std std-ref">Graham</span></a></p></td>
<td><p>34</p></td>
<td><p>rrg-bengioy-ad</p></td>
<td><p><em>various</em></p></td>
<td><p>–</p></td>
<td><p>–</p></td>
<td><p>def-bengioy</p></td>
</tr>
<tr class="row-even"><td><p><span class="xref std std-ref">Narval</span></p></td>
<td><p>34</p></td>
<td><p>rrg-bengioy-ad</p></td>
<td><p>A100-40G</p></td>
<td><p>185</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">a100</span></code></p></td>
<td><p>rrg-bengioy-ad</p></td>
</tr>
</tbody>
</table>
</section>
<section id="account-creation">
<h3>Account Creation<a class="headerlink" href="#account-creation" title="Permalink to this heading"></a></h3>
<p>To access the Compute Canada (CC) clusters you have to first create an account
at <a class="reference external" href="https://ccdb.computecanada.ca">https://ccdb.computecanada.ca</a>. Use a password with at least 8 characters,
mixed case letters, digits and special characters. Later you will be asked to
create another password with those rules, and it’s really convenient that the
two password are the same.</p>
<p>Then, you have to apply for a <code class="docutils literal notranslate"><span class="pre">role</span></code> at
<a class="reference external" href="https://ccdb.computecanada.ca/me/add_role">https://ccdb.computecanada.ca/me/add_role</a>, which basically means telling CC that
you are part of the lab so they know which cluster you can have access to, and
track your usage.</p>
<p>You will be asked for the CCRI (See screenshot below). Please reach out to your
sponsor to get the CCRI.</p>
<img alt="role.png" class="align-center" src="_images/role.png" />
<p>You will need to <strong>wait</strong> for your sponsor to accept before being able to login
to the CC clusters.</p>
</section>
<section id="clusters">
<h3>Clusters<a class="headerlink" href="#clusters" title="Permalink to this heading"></a></h3>
<dl>
<dt>Beluga:</dt><dd><p>(<a class="reference internal" href="#beluga"><span class="std std-ref">Mila doc</span></a>)
(<a class="reference external" href="https://docs.computecanada.ca/wiki/B%C3%A9luga/en">Compute Canada doc</a>)</p>
<p>For most students, Beluga is the best choice for both CPU and GPU jobs because
of larger allocations on this cluster.</p>
</dd>
<dt>Graham:</dt><dd><p>(<a class="reference internal" href="#graham"><span class="std std-ref">Mila doc</span></a>)
(<a class="reference external" href="https://docs.computecanada.ca/wiki/Graham/en">Compute Canada doc</a>)</p>
<p>Graham has recent T4 GPUs. It can be a good alternative to Beluga with similar characteristics.</p>
</dd>
<dt>Cedar:</dt><dd><p>(<a class="reference internal" href="#cedar"><span class="std std-ref">Mila doc</span></a>)
(<a class="reference external" href="https://docs.computecanada.ca/wiki/Cedar/en">Compute Canada doc</a>)</p>
<p>Cedar is a good alternative to Beluga if you absolutely need to have an internet connection
on the compute nodes.</p>
</dd>
<dt>Niagara:</dt><dd><p>(<a class="reference internal" href="#niagara"><span class="std std-ref">Mila doc</span></a>)
(<a class="reference external" href="https://docs.computecanada.ca/wiki/Niagara/en">Compute Canada doc</a>)</p>
<p>We do not have allocations on Niagara anymore but it remains a good alternative for CPU jobs.</p>
</dd>
</dl>
<section id="beluga">
<h4>Beluga<a class="headerlink" href="#beluga" title="Permalink to this heading"></a></h4>
<p>Beluga is a cluster located at <a class="reference external" href="https://www.etsmtl.ca/">ÉTS</a> in Montreal. It
uses SLURM to schedule jobs. Its full documentation can be found <a class="reference external" href="https://docs.computecanada.ca/wiki/Béluga/en">here</a>, and its current status <a class="reference external" href="http://status.computecanada.ca">here</a>.</p>
<p>You can access Beluga via ssh:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><style type="text/css">
span.prompt1:before {
  content: "$ ";
}
</style><span class="prompt1">ssh &lt;user&gt;@beluga.computecanada.ca</span>
</pre></div></div><p>Where <code class="docutils literal notranslate"><span class="pre">&lt;user&gt;</span></code> is the username you created previously (see <a class="reference internal" href="#account-creation">Account Creation</a>).</p>
<section id="launching-jobs">
<h5>Launching Jobs<a class="headerlink" href="#launching-jobs" title="Permalink to this heading"></a></h5>
<p>Users must specify the resource allocation Group Name using the flag
<code class="docutils literal notranslate"><span class="pre">--account=rrg-bengioy-ad</span></code>.  To launch a CPU-only job:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">sbatch --time<span class="o">=</span><span class="m">1</span>:0:0 --account<span class="o">=</span>rrg-bengioy-ad job.sh</span>
</pre></div></div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>The account name will differ based on your affiliation.</p>
</div>
<p>To launch a GPU job:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">sbatch --time<span class="o">=</span><span class="m">1</span>:0:0 --account<span class="o">=</span>rrg-bengioy-ad --gres<span class="o">=</span>gpu:1 job.sh</span>
</pre></div></div><p>And to get an interactive session, use the <code class="docutils literal notranslate"><span class="pre">salloc</span></code> command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">salloc --time<span class="o">=</span><span class="m">1</span>:0:0 --account<span class="o">=</span>rrg-bengioy-ad --gres<span class="o">=</span>gpu:1</span>
</pre></div></div><p>The full documentation for jobs launching on Beluga can be found <a class="reference external" href="https://docs.computecanada.ca/wiki/Running_jobs">here</a>.</p>
</section>
<section id="beluga-nodes-description">
<h5>Beluga nodes description<a class="headerlink" href="#beluga-nodes-description" title="Permalink to this heading"></a></h5>
<p>Each GPU node consists of:</p>
<ul class="simple">
<li><p>40 CPU cores</p></li>
<li><p>186 GB RAM</p></li>
<li><p>4 GPU NVIDIA V100 (16GB)</p></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You should ask for max 10 CPU cores and 32 GB of RAM per GPU you are
requesting (as explained <a class="reference external" href="https://docs.computecanada.ca/wiki/Allocations_and_resource_scheduling">here</a>),
otherwise, your job will count for more than 1 allocation, and will take
more time to get scheduled.</p>
</div>
</section>
<section id="beluga-storage">
<span id="cc-storage"></span><h5>Beluga Storage<a class="headerlink" href="#beluga-storage" title="Permalink to this heading"></a></h5>
<table class="docutils align-default">
<colgroup>
<col style="width: 29%" />
<col style="width: 32%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Storage</p></th>
<th class="head"><p>Path</p></th>
<th class="head"><p>Usage</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$HOME</span></code></p></td>
<td><p>/home/&lt;user&gt;/</p></td>
<td><ul class="simple">
<li><p>Code</p></li>
<li><p>Specific libraries</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">$HOME/projects</span></code></p></td>
<td><p>/project/rpp-bengioy</p></td>
<td><ul class="simple">
<li><p>Compressed raw datasets</p></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code></p></td>
<td><p>/scratch/&lt;user&gt;</p></td>
<td><ul class="simple">
<li><p>Processed datasets</p></li>
<li><p>Experimental results</p></li>
<li><p>Logs of experiments</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code></p></td>
<td></td>
<td><ul class="simple">
<li><p>Temporary job results</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>They are roughly listed in order of increasing performance and optimized for
different uses:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">$HOME</span></code> folder on NFS is appropriate for codes and libraries which are
small and read once. <strong>Do not write experiemental results here!</strong></p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">$HOME/projects</span></code> folder should only contain <strong>compressed raw</strong> datasets
(<strong>processed</strong> datasets should go in <code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code>). We have a limit on the
size and number of file in <code class="docutils literal notranslate"><span class="pre">$HOME/projects</span></code>, so do not put anything else
there.  If you add a new dataset there (make sure it is readable by every
member of the group using <code class="docutils literal notranslate"><span class="pre">chgrp</span> <span class="pre">-R</span> <span class="pre">rpp-bengioy</span> <span class="pre">&lt;dataset&gt;</span></code>).</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">$SCRATCH</span></code> space can be used for short term storage. It has good
performance and large quotas, but is purged regularly (every file that has
not been used in the last 3 months gets deleted, but you receive an email
before this happens).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">$SLURM_TMPDIR</span></code> points to the local disk of the node on which a job is
running. It should be used to copy the data on the node at the beginning of
the job and write intermediate checkpoints. This folder is cleared after each
job.</p></li>
</ul>
<p>When an experiment is finished, results should be transferred back to Mila
servers.</p>
<p>More details on storage can be found <a class="reference external" href="https://docs.computecanada.ca/wiki/B%C3%A9luga/en#Storage">here</a>.</p>
</section>
<section id="modules">
<h5>Modules<a class="headerlink" href="#modules" title="Permalink to this heading"></a></h5>
<p>Many software, such as Python or MATLAB are already compiled and available on
Beluga through the <code class="docutils literal notranslate"><span class="pre">module</span></code> command and its subcommands. Its full
documentation can be found <a class="reference external" href="https://docs.computecanada.ca/wiki/Utiliser_des_modules/en">here</a>.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 37%" />
<col style="width: 63%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>module avail</p></td>
<td><p>Displays all the available modules</p></td>
</tr>
<tr class="row-even"><td><p>module load &lt;module&gt;</p></td>
<td><p>Loads &lt;module&gt;</p></td>
</tr>
<tr class="row-odd"><td><p>module spider &lt;module&gt;</p></td>
<td><p>Shows specific details about &lt;module&gt;</p></td>
</tr>
</tbody>
</table>
<p>In particular, if you with to use <code class="docutils literal notranslate"><span class="pre">Python</span> <span class="pre">3.6</span></code> you can simply do:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">module load python/3.6</span>
</pre></div></div><div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you wish to use Python on the cluster, we strongly encourage you to
read <a class="reference external" href="https://docs.computecanada.ca/wiki/Python">CC Python Documentation</a>,
and in particular the <a class="reference external" href="https://docs.computecanada.ca/wiki/PyTorch">Pytorch</a>
and/or <a class="reference external" href="https://docs.computecanada.ca/wiki/TensorFlow">Tensorflow</a> pages.</p>
</div>
<p>The cluster has many Python packages (or <code class="docutils literal notranslate"><span class="pre">wheels</span></code>), such already compiled for
the cluster. See <a class="reference external" href="https://docs.computecanada.ca/wiki/Python/en">here</a> for the
details. In particular, you can browse the packages by doing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">avail_wheels &lt;wheel&gt;</span>
</pre></div></div><p>Such wheels can be installed using pip. Moreover, the most efficient way to use
modules on the cluster is to <a class="reference external" href="https://docs.computecanada.ca/wiki/Python#Creating_virtual_environments_inside_of_your_jobs">build your environnement inside your job</a>.
See the script example below.</p>
</section>
<section id="script-example">
<h5>Script Example<a class="headerlink" href="#script-example" title="Permalink to this heading"></a></h5>
<p>Here is a <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> script that follows good practices on Beluga:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="ch">#!/bin/bash</span>
<span class="linenos"> 2</span><span class="c1">#SBATCH --account=rrg-bengioy-ad         # Yoshua pays for your job</span>
<span class="linenos"> 3</span><span class="c1">#SBATCH --cpus-per-task=6                # Ask for 6 CPUs</span>
<span class="linenos"> 4</span><span class="c1">#SBATCH --gres=gpu:1                     # Ask for 1 GPU</span>
<span class="linenos"> 5</span><span class="c1">#SBATCH --mem=32G                        # Ask for 32 GB of RAM</span>
<span class="linenos"> 6</span><span class="c1">#SBATCH --time=3:00:00                   # The job will run for 3 hours</span>
<span class="linenos"> 7</span><span class="c1">#SBATCH -o /scratch/&lt;user&gt;/slurm-%j.out  # Write the log in $SCRATCH</span>
<span class="linenos"> 8</span>
<span class="linenos"> 9</span><span class="c1"># 1. Create your environement locally</span>
<span class="linenos">10</span>module load python/3.6
<span class="linenos">11</span>virtualenv --no-download <span class="nv">$SLURM_TMPDIR</span>/env
<span class="linenos">12</span><span class="nb">source</span> <span class="nv">$SLURM_TMPDIR</span>/env/bin/activate
<span class="linenos">13</span>pip install --no-index torch torchvision
<span class="linenos">14</span>
<span class="linenos">15</span><span class="c1"># 2. Copy your dataset on the compute node</span>
<span class="linenos">16</span><span class="c1"># IMPORTANT: Your dataset must be compressed in one single file (zip, hdf5, ...)!!!</span>
<span class="linenos">17</span>cp <span class="nv">$SCRATCH</span>/&lt;dataset.zip&gt; <span class="nv">$SLURM_TMPDIR</span>
<span class="linenos">18</span>
<span class="linenos">19</span><span class="c1"># 3. Eventually unzip your dataset</span>
<span class="linenos">20</span>unzip <span class="nv">$SLURM_TMPDIR</span>/&lt;dataset.zip&gt; -d <span class="nv">$SLURM_TMPDIR</span>
<span class="linenos">21</span>
<span class="linenos">22</span><span class="c1"># 4. Launch your job, tell it to save the model in $SLURM_TMPDIR</span>
<span class="linenos">23</span><span class="c1">#    and look for the dataset into $SLURM_TMPDIR</span>
<span class="linenos">24</span>python main.py --path <span class="nv">$SLURM_TMPDIR</span> --data_path <span class="nv">$SLURM_TMPDIR</span>
<span class="linenos">25</span>
<span class="linenos">26</span><span class="c1"># 5. Copy whatever you want to save on $SCRATCH</span>
<span class="linenos">27</span>cp <span class="nv">$SLURM_TMPDIR</span>/&lt;to_save&gt; <span class="nv">$SCRATCH</span>
</pre></div>
</div>
</section>
<section id="using-cometml-and-wandb">
<h5>Using CometML and Wandb<a class="headerlink" href="#using-cometml-and-wandb" title="Permalink to this heading"></a></h5>
<p>The compute nodes for Beluga don’t have access to the internet,
but there is a special module that can be loaded in order to allow
training scripts to access some specific servers, which includes
the necessary servers for using CometML and Wandb (“Weights and Biases”).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">module load httpproxy</span>
</pre></div></div><p>More documentation about this can be found <a class="reference external" href="https://docs.computecanada.ca/wiki/Weights_%26_Biases_(wandb)">here</a>.</p>
</section>
</section>
<section id="graham">
<h4>Graham<a class="headerlink" href="#graham" title="Permalink to this heading"></a></h4>
<p>Graham is a cluster located at University of Waterloo. It uses SLURM to schedule
jobs. Its full documentation can be found <a class="reference external" href="https://docs.computecanada.ca/wiki/Graham/">here</a>, and its current status <a class="reference external" href="http://status.computecanada.ca">here</a>.</p>
<p>You can access Graham via ssh:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">ssh &lt;user&gt;@graham.computecanada.ca</span>
</pre></div></div><p>Where <code class="docutils literal notranslate"><span class="pre">&lt;user&gt;</span></code> is the username you created previously (see <a class="reference internal" href="#account-creation">Account Creation</a>).</p>
<p>Since its structure is similar to <cite>Beluga</cite>, please look at the <a class="reference internal" href="#beluga">Beluga</a>
documentation, as well as relevant parts of the <a class="reference external" href="https://docs.computecanada.ca/wiki/Graham">Compute Canada Documentation</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For GPU jobs the ressource allocation Group Name is the same as Beluga, so you should use the flag <code class="docutils literal notranslate"><span class="pre">--account=rrg-bengioy-ad</span></code> for GPU jobs.</p>
</div>
</section>
<section id="cedar">
<h4>Cedar<a class="headerlink" href="#cedar" title="Permalink to this heading"></a></h4>
<p>Cedar is a cluster located at Simon Fraser University. It uses SLURM to schedule
jobs. Its full documentation can be found <a class="reference external" href="https://docs.computecanada.ca/wiki/Cedar">here</a>, and its current status <a class="reference external" href="http://status.computecanada.ca">here</a>.</p>
<p>You can access Cedar via ssh:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">ssh &lt;user&gt;@cedar.computecanada.ca</span>
</pre></div></div><p>Where <code class="docutils literal notranslate"><span class="pre">&lt;user&gt;</span></code> is the username you created previously (see <a class="reference internal" href="#account-creation">Account Creation</a>).</p>
<p>Since its structure is similar to <cite>Beluga</cite>, please look at the <a class="reference internal" href="#beluga">Beluga</a>
documentation, as well as relevant parts of the <a class="reference external" href="https://docs.computecanada.ca/wiki/Cedar">Compute Canada Documentation</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>However, we don’t have any CPU priority on Cedar, in this case you can
use <code class="docutils literal notranslate"><span class="pre">--account=def-bengioy</span></code> for CPU. Thus, it might take some time before
they start.</p>
</div>
</section>
<section id="niagara">
<h4>Niagara<a class="headerlink" href="#niagara" title="Permalink to this heading"></a></h4>
<p>Niagara is a cluster located at University of Toronto. It uses SLURM to schedule
jobs. Its full documentation can be found <a class="reference external" href="https://docs.computecanada.ca/wiki/Niagara">here</a>, and its current status <a class="reference external" href="http://status.computecanada.ca">here</a>.</p>
<p>You can access Niagara via ssh:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="prompt1">ssh &lt;user&gt;@niagara.computecanada.ca</span>
</pre></div></div><p>Where <code class="docutils literal notranslate"><span class="pre">&lt;user&gt;</span></code> is the username you created previously (see <a class="reference internal" href="#account-creation">Account Creation</a>).</p>
<p>Since its structure is similar to <cite>Beluga</cite>, please look at the <a class="reference internal" href="#beluga">Beluga</a>
documentation, as well as relevant parts of the <a class="reference external" href="https://docs.computecanada.ca/wiki/Niagara_Quickstart">Compute Canada Documentation</a>.</p>
</section>
</section>
<section id="faq">
<h3>FAQ<a class="headerlink" href="#faq" title="Permalink to this heading"></a></h3>
<section id="what-to-do-with-importerror-lib64-libm-so-6-version-glibc-2-23-not-found">
<h4>What to do with  <cite>ImportError: /lib64/libm.so.6: version GLIBC_2.23 not found</cite>?<a class="headerlink" href="#what-to-do-with-importerror-lib64-libm-so-6-version-glibc-2-23-not-found" title="Permalink to this heading"></a></h4>
<p>The structure of the file system is different than a classical Linux, so your
code has trouble finding libraries. See <a class="reference external" href="https://docs.computecanada.ca/wiki/Installing_software_in_your_home_directory#Installing_binary_packages">how to install binary packages</a>.</p>
</section>
<section id="disk-quota-exceeded-error-on-project-file-systems">
<h4>Disk quota exceeded error on <code class="docutils literal notranslate"><span class="pre">/project</span></code> file systems<a class="headerlink" href="#disk-quota-exceeded-error-on-project-file-systems" title="Permalink to this heading"></a></h4>
<p>You have files in <code class="docutils literal notranslate"><span class="pre">/project</span></code> with the wrong permissions. See <a class="reference external" href="https://docs.computecanada.ca/wiki/Frequently_Asked_Questions/en#Disk_quota_exceeded_error_on_.2Fproject_filesystems">how to change
permissions</a>.</p>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Information.html" class="btn btn-neutral float-left" title="Computing infrastructure and policies" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Userguide.html" class="btn btn-neutral float-right" title="User’s guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
<script type="text/javascript">
  window.onload = function() {
      $(".toggle > *").hide();
      $(".toggle .header").show();
      $(".toggle .header").click(function() {
          $(this).parent().children().not(".header").toggle(400);
          $(this).parent().children(".header").toggleClass("open");
      })
  };
</script>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>